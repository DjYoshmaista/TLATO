# main.py
"""
Main Orchestrator Script

Provides a command-line interface to interact with different subsystems
of the neural processing project (data processing, training, analysis, etc.).
"""

import logging
import random
import sys
import os
from pathlib import Path
import torch # Keep for potential direct use or type hinting

class SystemOrchestrator:
    """Handles the main CLI menu and orchestrates subsystem calls."""

    def __init__(self):
        logger.info("Initializing System Orchestrator...")
        # Config accessed via imported module: config.ClassName.ATTRIBUTE

    def show_main_menu(self):
        """Displays the main menu and handles user input."""
        while True:
            print("\n--- Neural System Orchestrator ---")
            print("1. Data Processing & Tokenization")
            print("2. Synthetic Data Generation")
            print("3. Model Training")
            print("4. Semantic Labeling (Example)")
            print("5. System Utilities")
            print("6. View System Logs")
            print("7. Exit System")
            print("---------------------------------")

            choice = input("Enter selection: ")

            try: # Wrap the entire menu action dispatch
                if choice == '1':
                    self.run_data_pipeline()
                elif choice == '2':
                    self.run_synthetic_data_generation()
                elif choice == '3':
                    self.run_training()
                elif choice == '4':
                    self.run_labeling_example()
                elif choice == '5':
                    self.system_utilities()
                elif choice == '6':
                    self.view_system_logs()
                elif choice == '7':
                    logger.info("System shutdown requested.")
                    print("Exiting Neural System Orchestrator.")
                    sys.exit(0)
                else:
                    print("Invalid selection. Please try again.")
            except KeyboardInterrupt: # Handle Ctrl+C gracefully
                 logger.warning("User interrupted execution (Ctrl+C). Exiting.")
                 print("\nOperation cancelled by user. Exiting.")
                 sys.exit(1)
            except Exception as e:
                 # Log the exception with traceback to all configured handlers
                 # (console, main log, error log)
                 logger.exception(f"Unhandled error during menu action '{choice}': {e}")
                 # Inform the user
                 log_file_path = LOG_FILE if 'LOG_FILE' in globals() else 'app.log' # Use actual log file path
                 print(f"\n!! An unexpected error occurred. Details logged to console and '{log_file_path}'. !!")
                 # Optionally wait for user input before showing menu again
                 # input("Press Enter to continue...")


    def run_data_pipeline(self):
        """Runs the data processing and tokenization pipeline."""
        if not DATA_PROCESSING_AVAILABLE:
            print("Data processing modules are not available.")
            logger.warning("Attempted to run data pipeline, but modules are missing.")
            return

        print("\n--- Data Processing Pipeline ---")
        try:
            processor = DataProcessor()
            print("Running data processing step (checking for 'discovered', 'error' files)...")
            logger.info("Starting DataProcessor.process_all()")
            processor.process_all()
            logger.info("DataProcessor.process_all() finished.")
            print("Data processing step finished.")

            tokenizer = Tokenizer()
            print("Running tokenization step (checking for 'processed' files)...")
            logger.info("Starting Tokenizer.tokenize_all()")
            tokenizer.tokenize_all()
            logger.info("Tokenizer.tokenize_all() finished.")
            print("Tokenization step finished.")
            print("------------------------------")

        except Exception as e:
             # Log with traceback
             logger.exception(f"Error during data pipeline: {e}")
             print(f"Data pipeline failed. Check logs.")

    def run_synthetic_data_generation(self):
        """Runs the synthetic data generation process."""
        if not SYNTHETIC_DATA_AVAILABLE:
            print("Synthetic data module is not available.")
            logger.warning("Attempted to run synthetic data generation, but module is missing.")
            return

        print("\n--- Synthetic Data Generation ---")
        target_samples = getattr(config.SyntheticDataConfig, 'TARGET_SAMPLES', 0)
        confirm = input(f"This will generate ~{target_samples} samples using the API. Continue? (y/n): ")
        if confirm.lower() != 'y':
            print("Synthetic data generation cancelled.")
            return

        try:
            generator = SyntheticDataGenerator()
            print("Starting synthetic data generation...")
            logger.info("Starting SyntheticDataGenerator.generate_dataset()")
            generator.generate_dataset()
            logger.info("SyntheticDataGenerator.generate_dataset() finished.")
            print("Synthetic data generation finished.")
            print("-------------------------------")
        except Exception as e:
            logger.exception(f"Error during synthetic data generation: {e}")
            print(f"Synthetic data generation failed. Check logs.")


    def run_training(self):
        """Initializes and runs the model training process."""
        if not TRAINING_AVAILABLE:
            print("Training modules are not available.")
            logger.warning("Attempted to run training, but modules are missing.")
            return

        print("\n--- Model Training ---")
        try:
            DEVICE = config.DEFAULT_DEVICE
            INPUT_DIM = 128 # Example - ideally from config if model structure varies
            NUM_CLASSES = 6   # Example - ideally from config

            print(f"Initializing model ({getattr(ZoneClassifier, '__name__', 'N/A')}) on device {DEVICE}...")
            model = ZoneClassifier(input_features=INPUT_DIM, num_classes=NUM_CLASSES, device=DEVICE)

            print("Initializing data loader...")
            tokenized_dir = getattr(config, 'TOKENIZED_DATA_DIR', './data/tokenized')
            data_loader = EnhancedDataLoader(device=DEVICE, data_dir=tokenized_dir)

            criterion = nn.MSELoss() # Example loss
            print(f"Using loss function: {type(criterion).__name__}")

            trainer = EnhancedTrainer(model=model, data_loader=data_loader, criterion=criterion, device=DEVICE)

            load_choice = input("Load checkpoint before training? (Enter filename or leave blank): ").strip()
            if load_choice:
                 if trainer.load_checkpoint(load_choice):
                      print(f"Checkpoint '{load_choice}' loaded successfully.")
                 else:
                      print(f"Failed to load checkpoint '{load_choice}'. Starting fresh training.")

            print("Starting training loop...")
            logger.info("Starting EnhancedTrainer.train()")
            trainer.train()
            logger.info("EnhancedTrainer.train() finished.")
            print("Training finished.")
            print("--------------------")

        except Exception as e:
            logger.exception(f"Error during training setup or execution: {e}")
            print(f"Training failed. Check logs.")


    def run_labeling_example(self):
        """Runs a simple example of the semantic labeler."""
        if not ANALYSIS_AVAILABLE:
            print("Analysis (labeler) module is not available.")
            logger.warning("Attempted to run labeling example, but module is missing.")
            return

        print("\n--- Semantic Labeling Example ---")
        try:
            labeler = SemanticLabeler()
            embedding_size = 768 # Example for bert-base-uncased
            dummy_embedding = torch.randn(embedding_size, device=config.DEFAULT_DEVICE)
            print(f"Generating label for a dummy embedding (size: {embedding_size})...")
            label = labeler.generate_label(dummy_embedding)
            print(f"Generated label: {label}")
            print("-------------------------------")

        except Exception as e:
            logger.exception(f"Error during labeling example: {e}")
            print(f"Labeling example failed. Check logs.")


    def system_utilities(self):
        """Displays the system utilities submenu."""
        while True:
            print("\n--- System Utilities ---")
            print("1. View Configuration")
            print("2. Randomize Some Parameters (Example)")
            print("3. Return to Main Menu")
            print("------------------------")

            choice = input("Select utility: ")

            if choice == '1':
                self.show_config()
            elif choice == '2':
                self.randomize_parameters_example()
            elif choice == '3':
                break
            else:
                print("Invalid selection.")

    def show_config(self):
        """Displays the current configuration loaded from src.utils.config."""
        print("\n--- Current Configuration ---")
        config_classes = {
            "Data Processing": getattr(config, 'DataProcessingConfig', None),
            "Data Loader": getattr(config, 'DataLoaderConfig', None),
            "Synthetic Data": getattr(config, 'SyntheticDataConfig', None),
            "Training": getattr(config, 'TrainingConfig', None),
            "Neural Zone": getattr(config, 'ZoneConfig', None),
            "Labeler": getattr(config, 'LabelerConfig', None),
            "Core/Attention": getattr(config, 'CoreConfig', None),
            "Testing": getattr(config, 'TestConfig', None),
            "Paths & General": None
        }
        for name, cfg_class in config_classes.items():
            print(f"\n# {name}:")
            if cfg_class:
                try:
                    cfg_instance = cfg_class()
                    for attr in dir(cfg_instance):
                         if not attr.startswith('_') and not callable(getattr(cfg_instance, attr)):
                              value = getattr(cfg_instance, attr)
                              print(f"  {attr}: {value}")
                except Exception as e:
                     print(f"  Could not display config for {name}: {e}")
            else:
                 for attr in dir(config):
                      if not attr.startswith('_') and attr.isupper():
                           value = getattr(config, attr)
                           if not isinstance(value, type) and not isinstance(value, type(config)):
                                print(f"  {attr}: {value}")
        print("---------------------------")


    def randomize_parameters_example(self):
        """Example of modifying parameters."""
        print("\n--- Parameter Randomization Example ---")
        print("NOTE: This only affects runtime values, not the config file.")
        try:
            new_lr = 10**random.uniform(-5, -3)
            print(f"Generated new LR (example): {new_lr:.6f}")
            print("Apply these values manually if desired.")
        except Exception as e:
             logger.exception(f"Error during parameter randomization example: {e}")
             print("Failed to randomize parameters.")
        print("-------------------------------------")


    def view_system_logs(self):
        """Displays the last N lines of the main log file."""
        log_file_path = LOG_FILE if 'LOG_FILE' in globals() else 'app.log'
        print(f"\n--- System Logs (Last 100 lines of {log_file_path}) ---")
        try:
            with open(log_file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
                for line in lines[-100:]:
                    print(line.strip())
        except FileNotFoundError:
            print(f"Log file not found: {log_file_path}")
        except Exception as e:
             logger.exception(f"Error reading log file {log_file_path}: {e}")
             print("Could not read log file.")
        print("------------------------------------------")

def main():
    # --- Add project root to sys.path ---
    # This allows imports like `from src.utils...` when running `python main.py` from project root
    project_root = Path(__file__).parent.resolve()
    sys.path.insert(0, str(project_root))
    # ------------------------------------

    # Import configuration and logger setup first
    # Assuming the modular structure with 'src'
    try:
        # Setup logger *before* importing other modules that might log during import
        from src.utils.logger import setup_logger, LOG_FILE
        setup_logger() # Configure logging system wide
        logger = logging.getLogger(__name__) # Get logger for main script AFTER setup

        from src.utils import config # Import the whole config module for easy access

    except ImportError as e:
         # Fallback if src structure isn't found
         print(f"[CRITICAL] Failed to import from src. Ensure 'src' directory exists and script is run from the project root. Error: {e}", file=sys.stderr)
         # Basic logging setup if main one failed
         logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
         logger = logging.getLogger(__name__)
         logger.critical("Failed to initialize core components from src. Limited functionality.")
         # Define fallbacks or exit if core components are essential
         LOG_FILE = Path("main_fallback.log") # type: ignore
         class config: # Dummy config
              class DataProcessingConfig: REPO_FILE = "fallback_repo.csv.zst"
              class SyntheticDataConfig: TARGET_SAMPLES = 0
              class TestConfig: pass
              DEFAULT_DEVICE = 'cpu'
              TOKENIZED_DATA_DIR = Path('./data/tokenized') # type: ignore

    # Now import other components using try-except
    try:
        from src.data.processing import DataProcessor, Tokenizer
        DATA_PROCESSING_AVAILABLE = True
    except ImportError as e:
        logger.warning(f"Data processing modules not fully available: {e}")
        DATA_PROCESSING_AVAILABLE = False
        class DataProcessor:
            def process_all(self):
                raise NotImplementedError("Module not loaded")
        class Tokenizer:
            def tokenize_all(self):
                raise NotImplementedError("Module not loaded")

    try:
        from src.data.synthetic import SyntheticDataGenerator
        SYNTHETIC_DATA_AVAILABLE = True
    except ImportError as e:
        logger.warning(f"Synthetic data module not available: {e}")
        SYNTHETIC_DATA_AVAILABLE = False
        class SyntheticDataGenerator:
            def generate_dataset(self):
                raise NotImplementedError("Module not loaded")

    try:
        from src.training.trainer import EnhancedTrainer
        from src.core.models import ZoneClassifier # Example model
        from src.data.loaders import EnhancedDataLoader # Example loader
        import torch.nn as nn # For loss function example
        TRAINING_AVAILABLE = True
    except ImportError as e:
        logger.warning(f"Training modules not fully available: {e}")
        TRAINING_AVAILABLE = False
        # Define dummy classes correctly, each on its own line
        class EnhancedTrainer:
            def train(self):
                raise NotImplementedError("Module not loaded")
            def load_checkpoint(self, fn):
                raise NotImplementedError("Module not loaded")
        class ZoneClassifier: pass
        class EnhancedDataLoader: pass
        # Define dummy nn structure correctly
        class _DummyNNModule: pass # Base dummy
        class _DummyMSELoss(_DummyNNModule): pass
        class nn: # Dummy nn module
            Module = _DummyNNModule
            MSELoss = _DummyMSELoss
    try:
        from src.analysis.labeler import SemanticLabeler
        ANALYSIS_AVAILABLE = True
    except ImportError as e:
        logger.warning(f"Analysis (labeler) module not available: {e}")
        ANALYSIS_AVAILABLE = False
        class SemanticLabeler:
            def generate_label(self, emb):
                raise NotImplementedError("Module not loaded")

    try:
        # Ensure Path is available if fallback config was used
        from pathlib import Path
        logger.info("--- System Orchestrator Started ---")
        orchestrator = SystemOrchestrator()
        try:
            orchestrator.show_main_menu()
        except Exception as main_err:
            # Catch any unexpected error in the main loop itself
            logger.critical(f"Critical error in main orchestrator loop: {main_err}", exc_info=True)
            print(f"\n!!! A critical error occurred: {main_err}. Check logs for details. Exiting. !!!")
            sys.exit(1)
        finally:
            # This will run even if sys.exit() was called
            logger.info("--- System Orchestrator Exiting ---")

if __name__ == "__main__":
    main()
